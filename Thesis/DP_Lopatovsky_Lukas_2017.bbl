\begin{thebibliography}{1}
\providecommand{\biburl}[1]{\url{#1}}
\providecommand{\urlprefix}{Available from: }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi:\discretionary{}{}{}#1}\else
  \providecommand{\doi}{doi:\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi
\providecommand{\selectlanguage}[1]{\relax}
\providecommand{\eprint}[2][]{\biburl{#2}}

\bibitem{Al11}
Allahverdyan, A.; Galstyan, A.: Comparative analysis of viterbi training and
  maximum likelihood estimation for hmms. In \emph{Advances in Neural
  Information Processing Systems}, 2011, pp. 1674--1682.

\bibitem{De77}
Dempster, A.~P.; Laird, N.~M.; Rubin, D.~B.: Maximum likelihood from incomplete
  data via the EM algorithm. \emph{Journal of the royal statistical society.
  Series B (methodological)}, 1977: pp. 1--38.

\bibitem{Do08}
Do, C.~B.; Batzoglou, S.: What is the expectation maximization algorithm?
  \emph{Nature biotechnology}, volume~26, no.~8, 2008: p. 897.

\bibitem{Sc01}
Jones, E.; Oliphant, T.; Peterson, P.; etc.: {SciPy}: Open source scientific
  tools for {Python}. 2001--, [Online; accessed 2017-05-03].
\urlprefix\biburl{http://www.scipy.org/}

\bibitem{Ka81}
Karlin, S.; Taylor, H.~E.: \emph{A second course in stochastic processes}.
  Elsevier, 1981.

\bibitem{Li15}
Liu, Y.-Y.; Li, S.; Li, F.; etc.: Efficient learning of continuous-time hidden
  markov models for disease progression. In \emph{Advances in neural
  information processing systems}, 2015, pp. 3600--3608.

\bibitem{Ra89}
Rabiner, L.~R.: A tutorial on hidden Markov models and selected applications in
  speech recognition. \emph{Proceedings of the IEEE}, volume~77, no.~2, 1989:
  pp. 257--286.

\end{thebibliography}
